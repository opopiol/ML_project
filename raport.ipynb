{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "raport.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1QjQ7tgEXZOWadktj3e3o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/opopiol/ML_project/blob/model/raport.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6BvWinAcIv1"
      },
      "source": [
        "### **1. EDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAWIVIuCci8_"
      },
      "source": [
        "\n",
        "\n",
        "*   Element listy\n",
        "*   Element listy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8g4G0P-EcuG"
      },
      "source": [
        "Data scaling is a recommended pre-processing step when working with many machine learning algorithms."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10zp9NPrcS5F"
      },
      "source": [
        "### **2. Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S84oo6uJCbRA",
        "outputId": "2473be29-919d-4224-fbca-41c93414fe62"
      },
      "source": [
        "y.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "y \n",
              " 1    3375\n",
              "-1     375\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPrfdiTFcmCq"
      },
      "source": [
        "The distribution of the labels is very uneven. They appear in proportions of about 1:10.\n",
        "\n",
        "Thatâ€™s why we decided to choose f1-score because it fits the best to our dataset and deals best with disproportion. This metric is the harmonic mean of the both precision and recall.\n",
        "\n",
        "And because we have to predict the class of given data we use classifiers. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmQxzc7scXKq"
      },
      "source": [
        "### **3. Baseline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wmz0L3A6e64Q"
      },
      "source": [
        "For the base model we choose `DummyClassifier()`, beacuase it is a simple baseline for the other classifiers. \n",
        "\n",
        "Strategies we used are `['stratified', 'most_frequent', 'constant', 'uniform']` and we get the following results:\n",
        "\n",
        "\n",
        "> `For stratified strategy f1 score is 0.8951813214108296 with labels: [-1  1]\n",
        "[[ 14  98]\n",
        " [111 902]]\n",
        "\n",
        "\n",
        "For most_frequent strategy f1 score is 0.9476145930776426 with labels: [1]\n",
        "[[   0  112]\n",
        " [   0 1013]]\n",
        "For prior strategy f1 score is 0.9476145930776426 with labels: [1]\n",
        "[[   0  112]\n",
        " [   0 1013]]\n",
        "For uniform strategy f1 score is 0.6650093225605965 with labels: [-1  1]\n",
        "[[ 60  52]\n",
        " [491 522]]`\n",
        "\n",
        "The highest results were achived by `most_frequent` strategy and `prior` strategy with a result above 94%. But both of them were only using one, majority class.\n",
        "\n",
        "For another baseline, we decided to check also `DecisionTreeClassifier()` and its f1 scora was above 96%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9I2AtyTcZsB"
      },
      "source": [
        "### **4. Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxoT9a4jcZxe"
      },
      "source": [
        "In the first approach to choosing the best class factor we decided to check the following three classifiers `LogisticRegression(random_state=0, max_iter = 1000)`, `KNeighborsClassifier()` and `SVC()`.\n",
        "\n",
        "Their f1 scores were:\n",
        "\n",
        "*   `LogisticRegression` 0.891662506240639\n",
        "*   `KNeighborsClassifier` 0.9803921568627452\n",
        "*   `SVC` 0.9767211490837047\n",
        "\n",
        "Because `LogisticRegression` achieved a result lower than the base, it was not taken into account further.\n",
        "\n",
        "`KNeighborsClassifier`, with its default number of 5 neighbors, performed the best out of three given classifiers. Also model is usually robust to noisy data.\n",
        "\n",
        "`SVC` also performed better f1 score than our base model. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0ymzjfe_sWc"
      },
      "source": [
        "Later we were looking for more advanced calssifiers. Some of the most popular are AdaBoost, Gradient Boosting, and XGBoost. Due to the long processing time, we decided to try only one- `AdaBoostClassifier()` to see what results it would achieve. In its basic model, without the given parameters, it achieved a f1 score 0.9656188605108056, so above baseline score.\n",
        "\n",
        "> In its basic model, without the given parameters, it achieved a f1 score 0.9656188605108056, so above baseline score.\n",
        "\n",
        "Then a pipeline was created to see which parameters of `AdaBoostClassifier()` performed best. In the pipeline were used: `'n_estimators': [50, 100, 150], 'learning_rate': [0.1, 0.01, 0.05]`. It was done in order not to overload the fan pipeline so much. \n",
        "\n",
        "> It turns out that the best parameters was `algorithm='SAMME.R', base_estimator=None, learning_rate=0.05, n_estimators=50, random_state=None`. The model achieved a score of 0.9793510324483775.\n",
        "\n",
        "These params were used in final pipeline with others classifiers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7jq40XPDi4q"
      },
      "source": [
        "The final pipeline had parameters and models choosen earlier.\n",
        "\n",
        "`PCA()` got n_components = 0.99, because with this params it performed the best in EDA's clustering.\n",
        "As scaler we got `StandardScaler()` same as in EDA.\n",
        "\n",
        "In pipeline three calssifier were checked: \n",
        "\n",
        "*   `SVC()` with `kernel: ['linear', 'poly'], class_weight: ['balanced'], and C: np.logspace(1,4,5)`\n",
        "*   `KNeighborsClassifier()` with `n_neighbors': [2, 4, 6, 8, 10], algorithm': ['auto']`\n",
        "*   `AdaBoostClassifier()` with the parameters that came out in the previous pipeline `n_estimators': [50], learning_rate': [0.1]`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}